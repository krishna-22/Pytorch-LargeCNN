{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0505_LargeCNNs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "DVR1FiuJ-BzX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KNf9CD2ytqH",
        "colab_type": "text"
      },
      "source": [
        "## Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKI47gsW1Ii",
        "colab_type": "text"
      },
      "source": [
        "1. Loading datasets - Transforming images\n",
        "2. VGG-16 with modification to network head\n",
        "3. Using pre-trained models\n",
        "4. Storing intermediate models\n",
        "5. Resnet\n",
        "6. Inception v3\n",
        "7. Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbZpqiiiylAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NBprN3Ry2NE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGzpz3oE1Ikz",
        "colab_type": "text"
      },
      "source": [
        "## Dataset, transforms, and visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9c57fNA5Wsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvsHorMPzISb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
        "                                        download=True, \n",
        "                                        transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
        "                                        download=True, \n",
        "                                        transform=transform_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0dOpKtiAG4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTNj3LQY4eTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfLwRIXH08tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEOz-75x1NGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "\n",
        "print(images[1].shape)\n",
        "print(labels[1].item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oBeIwYC1N3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img, title):\n",
        "    npimg = img.numpy() / 2 + 0.5\n",
        "    plt.figure(figsize=(batch_size, 1))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfk-SYLY1Sbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch_images(dataloader):\n",
        "    images, labels = next(iter(dataloader))\n",
        "    img = torchvision.utils.make_grid(images)\n",
        "    imshow(img, title=[str(x.item()) for x in labels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Zi_s3p1htN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(4):\n",
        "    show_batch_images(trainloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E-pnTG97DDz",
        "colab_type": "text"
      },
      "source": [
        "## Creating VGG-16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QMSp0gEJLow",
        "colab_type": "text"
      },
      "source": [
        "https://pytorch.org/docs/master/_modules/torchvision/models/vgg.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra33PbJS28P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvte5SSA7G7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg = models.vgg16_bn()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w-p73Tz9aZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vgg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1bQdxQz-Dil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vgg.features[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX9PohSB-1Dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vgg.classifier[6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koDRbWi8_ApT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_in_features = vgg.classifier[6].in_features\n",
        "mod_classifier = list(vgg.classifier.children())[:-1]\n",
        "mod_classifier.extend([nn.Linear(final_in_features, num_classes)])\n",
        "print(mod_classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vHjXi1j_glv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg.classifier = nn.Sequential(*mod_classifier)\n",
        "print(vgg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVR1FiuJ-BzX",
        "colab_type": "text"
      },
      "source": [
        "### Train CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKnlGE1q7JtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtRHmDs_BvZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation(dataloader, model):\n",
        "    total, correct = 0, 0\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htVdEliECDsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg = vgg.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.SGD(vgg.parameters(), lr=0.05)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSWnZJxjBbwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_epoch_arr = []\n",
        "max_epochs = 1\n",
        "\n",
        "n_iters = np.ceil(50000/batch_size)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs = vgg(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        del inputs, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('Iteration: %d/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n",
        "        \n",
        "    loss_epoch_arr.append(loss.item())\n",
        "        \n",
        "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (\n",
        "        epoch, max_epochs, \n",
        "        evaluation(testloader, vgg), evaluation(trainloader, vgg)))\n",
        "    \n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh4gREC-IGFB",
        "colab_type": "text"
      },
      "source": [
        "### Freeze layers of Convolutional Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aD1lt1qcJOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzniE5sKKlnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg = models.vgg16_bn(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzaHEHaczpWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in vgg.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFAhAvahzrRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_in_features = vgg.classifier[6].in_features\n",
        "vgg.classifier[6] = nn.Linear(final_in_features, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqXCJEiK0Z2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in vgg.parameters():\n",
        "    if param.requires_grad:\n",
        "        print(param.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH-99npmPRUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg = vgg.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.SGD(vgg.parameters(), lr=0.05)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HuWwxaxIMTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_epoch_arr = []\n",
        "max_epochs = 1\n",
        "\n",
        "n_iters = np.ceil(50000/batch_size)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs = vgg(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('Iteration: %d/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n",
        "            \n",
        "        del inputs, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    loss_epoch_arr.append(loss.item())\n",
        "        \n",
        "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (\n",
        "        epoch, max_epochs, \n",
        "        evaluation(testloader, vgg), evaluation(trainloader, vgg)))\n",
        "    \n",
        "    \n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeacSwlg5p2r",
        "colab_type": "text"
      },
      "source": [
        "### With model copies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-dZMeUTpAxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf0qM_-PlXl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_epoch_arr = []\n",
        "max_epochs = 1\n",
        "\n",
        "min_loss = 1000\n",
        "\n",
        "n_iters = np.ceil(50000/batch_size)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs = vgg(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        if min_loss > loss.item():\n",
        "            min_loss = loss.item()\n",
        "            best_model = copy.deepcopy(vgg.state_dict())\n",
        "            print('Min loss %0.2f' % min_loss)\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('Iteration: %d/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n",
        "            \n",
        "        del inputs, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    loss_epoch_arr.append(loss.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2GAOmBytwZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg.load_state_dict(best_model)\n",
        "print(evaluation(trainloader, vgg), evaluation(testloader, vgg))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83zNw_MLFBhd",
        "colab_type": "text"
      },
      "source": [
        "## ResNet Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJHZ2ibFGYfG",
        "colab_type": "text"
      },
      "source": [
        "https://pytorch.org/docs/master/_modules/torchvision/models/resnet.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYZJSHEKFDfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = models.resnet18(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMUoM7ToFFeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(resnet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1KOHDdtFoK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrL2ZlhrGwFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_features = resnet.fc.in_features\n",
        "resnet.fc = nn.Linear(in_features, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53REdyaaG8ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in resnet.parameters():\n",
        "    if param.requires_grad:\n",
        "        print(param.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQTZ3X_pG_tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = resnet.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.SGD(resnet.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rklYsln-Hcpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_epoch_arr = []\n",
        "max_epochs = 4\n",
        "\n",
        "min_loss = 1000\n",
        "\n",
        "n_iters = np.ceil(50000/batch_size)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs = resnet(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        if min_loss > loss.item():\n",
        "            min_loss = loss.item()\n",
        "            best_model = copy.deepcopy(resnet.state_dict())\n",
        "            print('Min loss %0.2f' % min_loss)\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('Iteration: %d/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n",
        "            \n",
        "        del inputs, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    loss_epoch_arr.append(loss.item())\n",
        "        \n",
        "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (\n",
        "        epoch, max_epochs, \n",
        "        evaluation(testloader, resnet), evaluation(trainloader, resnet)))\n",
        "    \n",
        "    \n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbetTwcrIMnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet.load_state_dict(best_model)\n",
        "print(evaluation(trainloader, resnet), evaluation(testloader, resnet))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asFT3q7vdDbd",
        "colab_type": "text"
      },
      "source": [
        "## Inception Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-gBu2zCGWE8",
        "colab_type": "text"
      },
      "source": [
        "https://pytorch.org/docs/master/_modules/torchvision/models/inception.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpAr08aGIOle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inception = models.inception_v3(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM_ACRUHdMfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(inception)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbu0JobP6ea9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in inception.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j31it2qX5Nfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aux_in_features = inception.AuxLogits.fc.in_features\n",
        "inception.AuxLogits.fc = nn.Linear(aux_in_features, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-M6nGOh6Xg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in inception.parameters():\n",
        "    if param.requires_grad:\n",
        "        print(param.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOI1Au2A6l9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_features = inception.fc.in_features\n",
        "inception.fc = nn.Linear(in_features, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF5pPlUS7I-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in inception.parameters():\n",
        "    if param.requires_grad:\n",
        "        print(param.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMSMZa_j7JXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(299), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(299), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYVy8C0H7vL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
        "                                        download=True, \n",
        "                                        transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
        "                                        download=True, \n",
        "                                        transform=transform_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkUGBe3x7zld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=16\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeKDmSV98QfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inception = inception.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.SGD(inception.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou_Q_JwK_fqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_inception(dataloader, model):\n",
        "    total, correct = 0, 0\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs, aux_outputs = model(inputs)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqmnOJqP75AK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_epoch_arr = []\n",
        "max_epochs = 1\n",
        "\n",
        "min_loss = 1000\n",
        "\n",
        "n_iters = np.ceil(50000/batch_size)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs, aux_outputs = inception(inputs)\n",
        "        loss = loss_fn(outputs, labels) + 0.3 * loss_fn(aux_outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        if min_loss > loss.item():\n",
        "            min_loss = loss.item()\n",
        "            best_model = copy.deepcopy(inception.state_dict())\n",
        "            print('Min loss %0.2f' % min_loss)\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('Iteration: %d/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n",
        "            \n",
        "        del inputs, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    loss_epoch_arr.append(loss.item())\n",
        "        \n",
        "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (\n",
        "        epoch, max_epochs, \n",
        "        evaluation_inception(testloader, inception), \n",
        "        evaluation_inception(trainloader, inception)))\n",
        "    \n",
        "    \n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfcUcxaL8T_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inception.load_state_dict(best_model)\n",
        "print(evaluation_inception(trainloader, inception), evaluation_inception(testloader, inception))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVxdZeh_JVVK",
        "colab_type": "text"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONIJxTuqJW1W",
        "colab_type": "text"
      },
      "source": [
        "1. Structure the above code into a series of functions and then call each model\n",
        "\n",
        "2. Try out different hyperparameter combinations and try to achieve published results on different networks\n",
        "\n",
        "3. Try out the CIFAR100 and STL10 datasets\n",
        "\n",
        "4. Try out another model - SqueezeNet\n",
        "\n",
        "5. Try training multiple layers and not just the last one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL9x2x9Dw9L5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}